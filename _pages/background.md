---
layout: archive
title: "Background"
permalink: /background/
author_profile: true
redirect_from:
  - /resume
  - /background
  - /cv
---

{% include base_path %}

## Education

**Ph.D. in Computer Science**, University of Illinois Urbana-Champaign  
*Expected May 2029*  
*Advisor: Prof. Cheng Xiang Zhai*

**B.S. in Computer Science**, Cornell University  
*May 2023*  
*Cum Laude with Honors in Computer Science*  
*Minor in Philosophy*  
*Humanities Scholar, LSAMP Scholar*


## Research Experience

**Research Assistant**, University of Illinois Urbana-Champaign  
*January 2024 - Present*  
*Advisor: Professor Cheng Xiang Zhai*  
*Project: "Hypergraph of Text for Structuring Document Collections"*


**SPI Fellow**, University of Illinois Urbana-Champaign  
*May 2023 - August 2023*  
*Advisor: Professor Tandy Warnow*  
*Title: "Community Search in Large Networks: Evaluating the State of the Art"*
* Designed and ran experiments evaluating k-core and k-truss community search algorithms
* Presented Findings at Illinois Summer Research Symposium

**Senior Thesis, Humanities Scholar Program**, Cornell University  
*August 2022 - May 2023*  
*Advisor: Professor Malte Ziewitz*  
*Title: "Exploring the Practice of Ethics by Machine Learning Practitioners in the Tech Industry"*
* Conducted hour-long semi-structured interviews with 10+ Machine Learning Professionals
* Presented findings at Humanities Scholars Undergraduate Research Conference

**Undergraduate Researcher**, Cornell University  
*Fall 2021 - Spring 2023*  
*Advisor: Professor Chris De Sa*  
*Project: Pruning Transformers with Interpolative Decompositions (Fall 2022 - Spring 2023)*
* Ran experiments testing ID pruning on LLMs such as BERT with various NLP tasks
* Experiments led to conference submission

*Project: Pruning CNNs for Transfer Learning (Spring 2022 - Summer 2022)*
* Ran experiments testing Interpolative Decompositions pruning in transfer learning domains
* Developed code allowing an iterative pruning process, an approach matching S.O.T.A performance

*Project: MCMC Neural Net Quantization (Fall 2021 - Spring 2022)*
* Ran experiments testing Gibbs sampling quantization on ResNet/Cifar10
* Developed code allowing for more accurate replication of training parameters specified in original ResNet paper

## Teaching Experience

**Teaching Assistant**  
*Advanced Information Retrieval, CS 510*  
*University of Illinois Urbana-Champaign, Spring 2025*

**Teaching Assistant**  
*Text Information Systems, CS 410*  
*University of Illinois Urbana-Champaign, Fall 2024*  

**Teaching Assistant**  
*Introduction to Machine Learning, CS 4780*  
*Cornell University, Fall 2022, Spring 2023*  


## Professional Experience

**Software Engineering Intern**  
*Talroo, Austin, TX (Summer 2025)*  
* Built distributed web crawling system using Apache Spark and Delta Lake to extract job postings from company career pages, achieving 18x performance improvement through async processing and intelligent load balancing
* Designed three-tier adaptive extraction pipeline (HTTP â†’ Browser LLM) with quality-based routing, achieving 94% recall accuracy on real-world validation tests against manually verified job counts
* Implemented distributed LLM request coordination system using Redis and Weighted Least Outstanding Requests algorithm, enabling zero rate-limit errors across multiple AI providers (OpenAI GPT-4, Google Gemini)
* Developed BERT classifier achieving 96% F1 score for job/non-job filtering to replace expensive LLM calls, significantly reducing API costs
* Created comprehensive robots.txt compliance system ensuring ethical crawling practices and sustainable long-term data access

**Core Data Infrastructure Software Engineering Intern**  
*Asana, Virtual Internship (Summer 2021)*  
* Completed in-depth data quality analysis enumerating benefits and ensuring safety of using new event logging code in production
* Prototyped logging for isolated spark clusters
* Created dataset size extractor for physical and external tables in order to expose dataset size to dataset consumers

**STEP Intern**  
*Google, Virtual Internship (Summer 2020)*  
* Collaborated with experts to research best methods for user embedding for our context
* Developed backend to web app feature allowing users to assess over and under-provisioning of a resource given some access management rule
* Rules were parsed and represented as an abstract syntax tree allowing for future rule optimization
* Created various utilities to help with data analysis including an efficient external sorting algorithm allowing for the sorting of datasets too big to fit into memory

**Deep Learning Engineer - Intern**  
*CACI International, Tampa, Florida (Summer 2019)*  
* Created new evaluation tools for computer vision experiments with added metrics
* Created script for building ImageNet into COCO style detection dataset
* Built tools to simulate low-shot learning on a full dataset
* Created Docker image to streamline usage of TensorFlow Object Detection API

**Junior Research Scientist**  
*CACI International, Tampa, Florida (Summer 2018)*  
* Researched the effect of class grouping on the performance of object detectors
* Experimented with many different architectures such as SSD, Faster-RCNN, and RetinaNet
* Built multiple datasets with different class groupings
* Modified dataset building script to allow for continuous writing decreasing memory usage substantially

## Honors and Awards

* NSF GRFP (Spring 2025)


## Involvements

**Co-Organizer**, TREC 2025 Product Search and Recommendations Track  
* Wrote and documented baseline results for product search task

